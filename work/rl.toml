###############
# stuff stuff #
###############
max_steps = 100

[deployment]
#inference_gpu_ids = [0,1,2,3,4,5]
#trainer_gpu_ids = [6,7]
type = "single_node"
gpus_per_node = 8
num_infer_gpus = 4
num_train_gpus = 4

[wandb]
project = "bb-cua-env"

[model]
name = "Qwen/Qwen3-VL-4B-Instruct"

######################
# orchestrator stuff #
######################
[orchestrator]
batch_size = 16
rollouts_per_example = 4
seq_len = 8000
oversampling_factor = 2.0
use_token_client = false

[orchestrator.sampling]
max_tokens = 2048

[[orchestrator.env]]
id = "webvoyager-no-anti-bot"
args = { keep_recent_screenshot = 2 }

#[orchestrator.val]
#interval = 5
#num_examples = 16

#################
# trainer stuff #
#################
[trainer.optim]
lr = 1e-5
weight_decay = 0.0

[trainer.model]
seq_len = 8000
optimization_dtype = "bfloat16"
reduce_dtype = "bfloat16"

#[trainer.model.ac]
#freq = 0

###################
# inference stuff #
###################
[inference]
gpu_memory_utilization = 0.7

[inference.model]
tool_call_parser = "hermes"
max_model_len = 8000
