# Inference config for testing elastic inference pool
# Usage: uv run python -m prime_rl.inference.server --config test_elastic_infer.toml

[model]
name = "PrimeIntellect/Qwen3-0.6B-Reverse-Text-SFT"
enforce_eager = true

[server]
port = 8000

enable_lora = true
gpu_memory_utilization = 0.5
