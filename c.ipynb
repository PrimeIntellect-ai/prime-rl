{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/prime-rl/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:09 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 14:25:11,257\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-03 14:25:13 [INFER] [INFO] Created node (ff87a0b0a3c7c0ce827e9cada5ff79e75a44a0633bfcb5b50f99307ddb26b337)\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:13Z \u001b[1m\u001b[31mERROR\u001b[0m iroh::discovery::pkarr\u001b[90m]\u001b[0m pkarr_publish; me=ff87a0b0a3\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:13Z \u001b[1m\u001b[31mERROR\u001b[0m tracing::span\u001b[90m]\u001b[0m magicsock;\n",
      "06-03 14:25:13 [INFER] [INFO] Setting up outgoing connection to ee1aa49a4459dfe813a3cf6eb882041230c7b2558469de81f87c9bf23bf10a03\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:13Z \u001b[1m\u001b[31mERROR\u001b[0m iroh::discovery\u001b[90m]\u001b[0m discovery; me=ff87a0b0a3 node=ee1aa49a44\n",
      "06-03 14:25:14 [INFER] [INFO] Outgoing connection to ee1aa49a4459dfe813a3cf6eb882041230c7b2558469de81f87c9bf23bf10a03 successful!\n",
      "06-03 14:25:14 [INFER] [INFO] Waiting for incoming connection...\n",
      "06-03 14:25:15 [INFER] [INFO] All connections successful!\n",
      "06-03 14:25:15 [INFER] [INFO] Patching model init for pp.rank=1 in pp.world_size=2\n"
     ]
    }
   ],
   "source": [
    "from src.zeroband.inference.pipeline import PipelineConfig, patch_model_load, setup_comm, setup_hooks\n",
    "\n",
    "config = PipelineConfig(\n",
    "    rank=1,\n",
    "    world_size=2,\n",
    "    iroh_seed=1,\n",
    "    iroh_peer_id=\"ee1aa49a4459dfe813a3cf6eb882041230c7b2558469de81f87c9bf23bf10a03\",\n",
    "    connection_num_retries=3,\n",
    ")\n",
    "\n",
    "node = setup_comm(config)\n",
    "patch_model_load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:22 [config.py:717] This model supports multiple tasks: {'reward', 'generate', 'classify', 'embed', 'score'}. Defaulting to 'generate'.\n",
      "WARNING 06-03 14:25:22 [arg_utils.py:1658] --disable-async-output-proc is not supported by the V1 Engine. Falling back to V0. We recommend to remove --disable-async-output-proc from your config in favor of the V1 Engine.\n",
      "INFO 06-03 14:25:23 [config.py:1770] Defaulting to use mp for distributed inference\n",
      "INFO 06-03 14:25:23 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='Qwen/Qwen3-0.6B', speculative_config=None, tokenizer='Qwen/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir='/alloc', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen3-0.6B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
      "WARNING 06-03 14:25:23 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 104 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:23 [multiproc_worker_utils.py:225] Worker ready; awaiting tasks\n",
      "INFO 06-03 14:25:23 [cuda.py:292] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:23 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 06-03 14:25:28 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:28 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 06-03 14:25:28 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:28 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 06-03 14:25:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_2,3.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_2,3.json\n",
      "INFO 06-03 14:25:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_05c76fde'), local_subscribe_addr='ipc:///tmp/5ec7a669-58be-4d05-8885-77a36a64b317', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 06-03 14:25:30 [parallel_state.py:1006] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [parallel_state.py:1006] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "INFO 06-03 14:25:30 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "INFO 06-03 14:25:30 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 06-03 14:25:30 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:30 [loader.py:458] Loading weights took 0.09 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.252847 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:30 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:30 [loader.py:458] Loading weights took 0.09 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:31 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.461013 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual is None\n",
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 14\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [3.0625, -0.328125, -2.203125, 1.7734375, 1.546875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [2.21875, -0.1982421875, 1.3203125, 0.451171875, -2.3125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 15\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.90625, 1.328125, 1.9453125, -0.50390625, -1.953125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [7.6875, 2.375, -1.75, 4.65625, 0.5703125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 16\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-2.296875, -0.2578125, 0.080078125, 1.046875, -1.0078125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [12.0, 3.9375, 1.4140625, 5.40625, -2.109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 17\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-1.421875, 0.98046875, 1.515625, -3.125, 0.0703125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [9.375, 0.78125, 4.03125, 10.5, -3.71875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 18\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.271484375, 1.5390625, -2.453125, -1.265625, 0.8515625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [6.875, -0.921875, 7.0625, 14.3125, 1.75]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 19\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.515625, -1.4140625, 1.546875, -3.15625, -1.78125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [6.78125, 3.25, 3.875, 20.75, 6.5]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 20\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.734375, 1.5390625, -0.4453125, -2.859375, 1.96875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [5.9375, -4.71875, 4.875, 19.5, 1.71875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 21\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.1796875, -1.5, 0.0, -1.7890625, 1.140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [7.8125, 1.375, 3.140625, 22.125, 7.25]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 22\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.7890625, -4.75, -7.75, 0.02734375, 0.4921875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [3.125, 6.1875, 4.375, 16.375, 14.25]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 23\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [3.0, -2.78125, -2.78125, 1.125, 3.375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-0.5625, -7.3125, -4.3125, 3.875, 13.125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 24\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-5.0625, -2.375, 7.6875, 6.8125, 2.734375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [10.25, -8.875, -5.59375, 21.0, 27.625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 25\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.58984375, -0.375, 2.953125, -7.875, -5.125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [3.8125, -3.1875, 21.625, 43.25, 58.5]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 26\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [2.203125, 0.546875, -0.9375, 3.625, 6.5625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [1.15625, -2.0625, 13.5625, 40.75, 54.5]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 27\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.4765625, -7.3125, -6.0625, -1.671875, -3.625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-4.375, 6.625, 43.0, 59.25, 74.0]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.6953125, -0.09716796875, 5.15625, 8.375, 10.125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-4.84375, -0.6875, 37.0, 57.5, 70.5]\n",
      "Layer 14\n",
      "hidden_states[-1][-5:]: [3.0625, -0.328125, -2.203125, 1.7734375, 1.546875]\n",
      "residual[-1][-5:]: [2.21875, -0.1982421875, 1.3203125, 0.451171875, -2.3125]\n",
      "Layer 15\n",
      "hidden_states[-1][-5:]: [0.90625, 1.328125, 1.9453125, -0.50390625, -1.953125]\n",
      "residual[-1][-5:]: [7.6875, 2.375, -1.75, 4.65625, 0.5703125]\n",
      "Layer 16\n",
      "hidden_states[-1][-5:]: [-2.296875, -0.2578125, 0.080078125, 1.046875, -1.0078125]\n",
      "residual[-1][-5:]: [12.0, 3.9375, 1.4140625, 5.40625, -2.109375]\n",
      "Layer 17\n",
      "hidden_states[-1][-5:]: [-1.421875, 0.98046875, 1.515625, -3.125, 0.0703125]\n",
      "residual[-1][-5:]: [9.375, 0.78125, 4.03125, 10.5, -3.71875]\n",
      "Layer 18\n",
      "hidden_states[-1][-5:]: [-0.271484375, 1.5390625, -2.453125, -1.265625, 0.8515625]\n",
      "residual[-1][-5:]: [6.875, -0.921875, 7.0625, 14.3125, 1.75]\n",
      "Layer 19\n",
      "hidden_states[-1][-5:]: [1.515625, -1.4140625, 1.546875, -3.15625, -1.78125]\n",
      "residual[-1][-5:]: [6.78125, 3.25, 3.875, 20.75, 6.5]\n",
      "Layer 20\n",
      "hidden_states[-1][-5:]: [1.734375, 1.5390625, -0.4453125, -2.859375, 1.96875]\n",
      "residual[-1][-5:]: [5.9375, -4.71875, 4.875, 19.5, 1.71875]\n",
      "Layer 21\n",
      "hidden_states[-1][-5:]: [1.1796875, -1.5, 0.0, -1.7890625, 1.140625]\n",
      "residual[-1][-5:]: [7.8125, 1.375, 3.140625, 22.125, 7.25]\n",
      "Layer 22\n",
      "hidden_states[-1][-5:]: [-0.7890625, -4.75, -7.75, 0.02734375, 0.4921875]\n",
      "residual[-1][-5:]: [3.125, 6.1875, 4.375, 16.375, 14.25]\n",
      "Layer 23\n",
      "hidden_states[-1][-5:]: [3.0, -2.78125, -2.78125, 1.125, 3.375]\n",
      "residual[-1][-5:]: [-0.5625, -7.3125, -4.3125, 3.875, 13.125]\n",
      "Layer 24\n",
      "hidden_states[-1][-5:]: [-5.0625, -2.375, 7.6875, 6.8125, 2.734375]\n",
      "residual[-1][-5:]: [10.25, -8.875, -5.59375, 21.0, 27.625]\n",
      "Layer 25\n",
      "hidden_states[-1][-5:]: [0.58984375, -0.375, 2.953125, -7.875, -5.125]\n",
      "residual[-1][-5:]: [3.8125, -3.1875, 21.625, 43.25, 58.5]\n",
      "Layer 26\n",
      "hidden_states[-1][-5:]: [2.203125, 0.546875, -0.9375, 3.625, 6.5625]\n",
      "residual[-1][-5:]: [1.15625, -2.0625, 13.5625, 40.75, 54.5]\n",
      "Layer 27\n",
      "hidden_states[-1][-5:]: [-0.4765625, -7.3125, -6.0625, -1.671875, -3.625]\n",
      "residual[-1][-5:]: [-4.375, 6.625, 43.0, 59.25, 74.0]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-0.6953125, -0.09716796875, 5.15625, 8.375, 10.125]\n",
      "residual[-1][-5:]: [-4.84375, -0.6875, 37.0, 57.5, 70.5]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] Memory profiling takes 1.94 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.57GiB; PyTorch activation peak memory takes 0.33GiB; the rest of the memory reserved for KV Cache is 68.93GiB.\n",
      "INFO 06-03 14:25:33 [worker.py:287] Memory profiling takes 2.04 seconds\n",
      "INFO 06-03 14:25:33 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 06-03 14:25:33 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.82GiB; PyTorch activation peak memory takes 1.44GiB; the rest of the memory reserved for KV Cache is 67.56GiB.\n",
      "INFO 06-03 14:25:33 [executor_base.py:112] # cuda blocks: 79068, # CPU blocks: 4681\n",
      "INFO 06-03 14:25:33 [executor_base.py:117] Maximum concurrency for 16384 tokens per request: 77.21x\n",
      "INFO 06-03 14:25:36 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 5.09 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    tensor_parallel_size=2,\n",
    "    max_seq_len_to_capture=16384,\n",
    "    max_model_len=16384,\n",
    "    quantization=None,\n",
    "    enforce_eager=True,\n",
    "    disable_async_output_proc=True,\n",
    "    download_dir=\"/alloc\",\n",
    "    dtype=\"bfloat16\")\n",
    "\n",
    "setup_hooks(config, llm, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, est. speed input: 14.15 toks/s, output: 3.54 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 14\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.1875, -0.28515625, -0.4453125, 1.5, 1.2265625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [2.09375, 0.55078125, 0.314453125, -0.2255859375, -1.90625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 15\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.0234375, -0.75390625, 1.3125, -1.9296875, -2.53125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [5.6875, 0.9453125, -0.416015625, 1.6875, -1.8515625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 16\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.6796875, -0.482421875, 0.74609375, -3.34375, 0.38671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [3.515625, -2.59375, 2.5, -0.423828125, -3.5]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 17\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-1.15625, 1.9375, 1.046875, -2.1875, 0.88671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [4.25, -3.1875, 3.46875, -4.4375, -2.984375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 18\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.453125, -2.203125, -4.09375, -0.2421875, -0.46875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [2.921875, -3.828125, 6.375, -6.5625, -3.40625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 19\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.86328125, -0.53515625, 0.1357421875, -0.1865234375, -2.359375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [6.375, -3.59375, 1.46875, -4.96875, -1.28125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 20\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [0.8125, 0.21875, 2.875, -3.359375, 1.1484375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [4.6875, -3.078125, -1.0234375, -7.0625, -7.1875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 21\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-4.375, -0.8984375, -0.1015625, 2.421875, -2.0]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [1.25, -2.25, -0.1328125, -16.0, -7.09375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 22\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.177734375, 0.69921875, 2.3125, -2.234375, 2.203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-4.65625, -0.28125, -1.8203125, -13.5625, -8.375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 23\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-0.58203125, -2.4375, 3.671875, 5.59375, 3.21875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-8.0625, -5.40625, 2.8125, -19.125, -11.25]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 24\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [1.265625, -0.79296875, 8.25, -1.4921875, -1.078125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-18.5, -8.5625, 3.015625, -15.0, -11.75]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 25\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-3.15625, -1.296875, 0.90625, 8.5625, 0.5859375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-19.5, -3.3125, 12.8125, -8.4375, -15.125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 26\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [2.3125, -2.25, -2.234375, 1.21875, -0.7578125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-21.0, 7.5, 25.625, 3.75, -8.125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m Layer 27\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-4.625, 4.25, 4.5, -8.9375, 6.25]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-21.625, -0.1875, 14.6875, 8.3125, 1.375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m hidden_states[-1][-5:]: [-4.84375, 0.7421875, 3.46875, -0.11767578125, 1.4140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367169)\u001b[0;0m residual[-1][-5:]: [-26.25, 4.0625, 19.25, -0.625, 7.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Got hidden_states and residuals (torch.Size([4, 1024]), torch.Size([4, 1024])) (16544 bytes)\n",
      "hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "residuals[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "Layer 14\n",
      "hidden_states[-1][-5:]: [0.1875, -0.28515625, -0.4453125, 1.5, 1.2265625]\n",
      "residual[-1][-5:]: [1.4765625, 1.484375, 0.734375, 0.66796875, -1.171875]\n",
      "Layer 15\n",
      "hidden_states[-1][-5:]: [-0.0234375, -0.75390625, 1.3125, -1.9296875, -2.53125]\n",
      "residual[-1][-5:]: [5.0625, 1.8828125, 0.00390625, 2.59375, -1.1171875]\n",
      "Layer 16\n",
      "hidden_states[-1][-5:]: [1.6796875, -0.482421875, 0.74609375, -3.34375, 0.38671875]\n",
      "residual[-1][-5:]: [2.890625, -1.65625, 2.921875, 0.482421875, -2.78125]\n",
      "Layer 17\n",
      "hidden_states[-1][-5:]: [-1.15625, 1.9375, 1.046875, -2.1875, 0.88671875]\n",
      "residual[-1][-5:]: [3.625, -2.25, 3.890625, -3.53125, -2.265625]\n",
      "Layer 18\n",
      "hidden_states[-1][-5:]: [1.453125, -2.203125, -4.09375, -0.2421875, -0.46875]\n",
      "residual[-1][-5:]: [2.296875, -2.890625, 6.8125, -5.65625, -2.6875]\n",
      "Layer 19\n",
      "hidden_states[-1][-5:]: [-0.86328125, -0.53515625, 0.1357421875, -0.1865234375, -2.359375]\n",
      "residual[-1][-5:]: [5.75, -2.65625, 1.90625, -4.0625, -0.5625]\n",
      "Layer 20\n",
      "hidden_states[-1][-5:]: [0.8125, 0.21875, 2.875, -3.359375, 1.1484375]\n",
      "residual[-1][-5:]: [4.0625, -2.140625, -0.578125, -6.15625, -6.5]\n",
      "Layer 21\n",
      "hidden_states[-1][-5:]: [-4.375, -0.8984375, -0.1015625, 2.421875, -2.0]\n",
      "residual[-1][-5:]: [0.625, -1.3203125, 0.3125, -15.0625, -6.40625]\n",
      "Layer 22\n",
      "hidden_states[-1][-5:]: [-0.177734375, 0.69921875, 2.3125, -2.234375, 2.203125]\n",
      "residual[-1][-5:]: [-5.28125, 0.65625, -1.375, -12.625, -7.65625]\n",
      "Layer 23\n",
      "hidden_states[-1][-5:]: [-0.58203125, -2.4375, 3.671875, 5.59375, 3.21875]\n",
      "residual[-1][-5:]: [-8.6875, -4.4375, 3.265625, -18.125, -10.5]\n",
      "Layer 24\n",
      "hidden_states[-1][-5:]: [1.265625, -0.79296875, 8.25, -1.4921875, -1.078125]\n",
      "residual[-1][-5:]: [-19.125, -7.59375, 3.453125, -14.0, -11.0]\n",
      "Layer 25\n",
      "hidden_states[-1][-5:]: [-3.15625, -1.296875, 0.90625, 8.5625, 0.5859375]\n",
      "residual[-1][-5:]: [-20.25, -2.3125, 13.25, -7.4375, -14.375]\n",
      "Layer 26\n",
      "hidden_states[-1][-5:]: [2.3125, -2.25, -2.234375, 1.21875, -0.7578125]\n",
      "residual[-1][-5:]: [-21.75, 8.5, 26.0, 4.75, -7.375]\n",
      "Layer 27\n",
      "hidden_states[-1][-5:]: [-4.625, 4.25, 4.5, -8.9375, 6.25]\n",
      "residual[-1][-5:]: [-22.375, 0.8125, 15.0625, 9.3125, 2.125]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-5.0, 0.92578125, 3.515625, 0.07080078125, 1.5546875]\n",
      "residual[-1][-5:]: [-27.0, 5.0625, 19.5, 0.375, 8.375]\n",
      "族自治县\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=1,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    seed=42,\n",
    ")\n",
    "request_outputs = llm.generate(\"Hello, world!\", sampling_params)\n",
    "print(request_outputs[0].outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
