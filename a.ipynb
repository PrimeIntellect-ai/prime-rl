{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/prime-rl/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:04:41 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 14:04:43,077\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:04:49 [config.py:717] This model supports multiple tasks: {'reward', 'embed', 'generate', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 06-03 14:04:49 [arg_utils.py:1658] --disable-async-output-proc is not supported by the V1 Engine. Falling back to V0. We recommend to remove --disable-async-output-proc from your config in favor of the V1 Engine.\n",
      "INFO 06-03 14:04:49 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='Qwen/Qwen3-0.6B', speculative_config=None, tokenizer='Qwen/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir='/alloc', load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen3-0.6B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
      "INFO 06-03 14:04:51 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 06-03 14:04:54 [parallel_state.py:1006] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 06-03 14:04:54 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "INFO 06-03 14:04:54 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 06-03 14:04:54 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.51it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:04:55 [loader.py:458] Loading weights took 0.26 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:04:55 [model_runner.py:1140] Model loading took 1.1201 GiB and 0.421287 seconds\n",
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [-0.045166015625, -0.0194091796875, 0.060791015625, -0.08251953125, -0.027099609375]\n",
      "residual[-1][-5:]: [0.1123046875, 0.1142578125, 0.07373046875, 0.1279296875, -0.0001220703125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.019287109375, 0.1640625, -0.212890625, 0.146484375, -0.26171875]\n",
      "residual[-1][-5:]: [-0.0078125, -0.08984375, -0.0595703125, -0.287109375, -0.1552734375]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.31640625, -0.03125, 0.8359375, -2.15625, -3.578125]\n",
      "residual[-1][-5:]: [-0.291015625, -0.51171875, -0.86328125, -0.59765625, 0.16015625]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.0001468658447265625, 0.0018463134765625, 0.002105712890625, -0.0001220703125, -0.006988525390625]\n",
      "residual[-1][-5:]: [0.10107421875, -0.625, 0.028076171875, -2.78125, -3.46875]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.0020599365234375, 0.005035400390625, 0.0026702880859375, -0.000640869140625, -0.0020294189453125]\n",
      "residual[-1][-5:]: [0.140625, -0.61328125, 0.0245361328125, -2.796875, -3.5]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.002593994140625, 0.00689697265625, 0.0024261474609375, -0.005462646484375, -0.005218505859375]\n",
      "residual[-1][-5:]: [0.224609375, -0.62109375, 0.0008544921875, -2.765625, -3.609375]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.003204345703125, 0.005523681640625, -0.00042724609375, -5.936622619628906e-05, -0.0020294189453125]\n",
      "residual[-1][-5:]: [0.2294921875, -0.5859375, -0.1171875, -2.765625, -3.671875]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.006500244140625, -0.004669189453125, 0.00225830078125, 0.0150146484375, 0.005096435546875]\n",
      "residual[-1][-5:]: [0.3671875, -0.6484375, -0.04638671875, -2.734375, -3.8125]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [0.000293731689453125, -0.00299072265625, -0.0015716552734375, -0.00040435791015625, 0.00262451171875]\n",
      "residual[-1][-5:]: [0.361328125, -0.640625, 0.0048828125, -2.859375, -3.921875]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.003143310546875, 0.00726318359375, 0.00885009765625, 0.005279541015625, 0.000507354736328125]\n",
      "residual[-1][-5:]: [0.19921875, -0.53515625, -0.11328125, -2.890625, -4.0625]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [0.00994873046875, 0.007537841796875, 0.0103759765625, 0.01116943359375, -0.00063323974609375]\n",
      "residual[-1][-5:]: [0.33984375, -0.2578125, -0.10791015625, -2.65625, -4.09375]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.0015411376953125, -0.0021209716796875, -0.00286865234375, -0.00099945068359375, 0.0021820068359375]\n",
      "residual[-1][-5:]: [0.390625, -0.298828125, -0.275390625, -2.59375, -4.3125]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.0028228759765625, -0.005401611328125, 0.006805419921875, 0.0014495849609375, -0.0023193359375]\n",
      "residual[-1][-5:]: [0.498046875, -0.25, -0.298828125, -2.453125, -4.25]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [0.004791259765625, -0.007598876953125, 0.0078125, 0.008056640625, 0.0036163330078125]\n",
      "residual[-1][-5:]: [0.63671875, -0.283203125, -0.34765625, -2.5, -4.0625]\n",
      "Layer 14\n",
      "hidden_states[-1][-5:]: [0.01806640625, 0.00799560546875, 0.01055908203125, 0.009033203125, 0.0050048828125]\n",
      "residual[-1][-5:]: [0.5078125, -0.26953125, -0.322265625, -2.421875, -4.03125]\n",
      "Layer 15\n",
      "hidden_states[-1][-5:]: [0.000743865966796875, 0.000675201416015625, 0.0089111328125, 0.011474609375, -0.007232666015625]\n",
      "residual[-1][-5:]: [0.49609375, -0.515625, -0.015625, -2.59375, -3.65625]\n",
      "Layer 16\n",
      "hidden_states[-1][-5:]: [0.0036773681640625, 0.0021209716796875, -0.00049591064453125, -0.0028228759765625, 0.021728515625]\n",
      "residual[-1][-5:]: [0.62890625, -1.34375, 0.166015625, -2.8125, -3.421875]\n",
      "Layer 17\n",
      "hidden_states[-1][-5:]: [0.0230712890625, 0.0400390625, 0.08935546875, -0.01123046875, -0.01092529296875]\n",
      "residual[-1][-5:]: [0.4296875, -1.5, -0.0927734375, -2.953125, -3.5]\n",
      "Layer 18\n",
      "hidden_states[-1][-5:]: [0.10595703125, 0.01556396484375, 0.037353515625, 0.01806640625, 0.119140625]\n",
      "residual[-1][-5:]: [0.6796875, -1.4765625, -0.21875, -3.0625, -3.421875]\n",
      "Layer 19\n",
      "hidden_states[-1][-5:]: [0.38671875, 0.451171875, 0.89453125, 0.55859375, 0.2734375]\n",
      "residual[-1][-5:]: [0.9140625, -1.5859375, -0.2734375, -3.296875, -3.21875]\n",
      "Layer 20\n",
      "hidden_states[-1][-5:]: [0.0205078125, 0.040771484375, -0.057861328125, -0.001983642578125, 0.007659912109375]\n",
      "residual[-1][-5:]: [1.5859375, -1.3125, 0.828125, -2.5, -3.46875]\n",
      "Layer 21\n",
      "hidden_states[-1][-5:]: [-0.01153564453125, 0.009033203125, 0.002532958984375, -0.0703125, -0.0223388671875]\n",
      "residual[-1][-5:]: [1.515625, -1.65625, 0.337890625, -2.75, -3.421875]\n",
      "Layer 22\n",
      "hidden_states[-1][-5:]: [0.06982421875, 0.032470703125, -0.00958251953125, -0.0517578125, 0.048828125]\n",
      "residual[-1][-5:]: [1.4140625, -1.484375, 0.51953125, -3.046875, -3.546875]\n",
      "Layer 23\n",
      "hidden_states[-1][-5:]: [0.025390625, 0.041015625, 0.00142669677734375, 0.04296875, -0.029052734375]\n",
      "residual[-1][-5:]: [1.84375, -1.6328125, 0.45703125, -2.953125, -4.03125]\n",
      "Layer 24\n",
      "hidden_states[-1][-5:]: [-0.04150390625, -0.037109375, 0.1611328125, 0.0419921875, -0.10546875]\n",
      "residual[-1][-5:]: [1.8359375, -1.1328125, 0.44140625, -2.796875, -3.40625]\n",
      "Layer 25\n",
      "hidden_states[-1][-5:]: [0.064453125, -0.0267333984375, -0.0986328125, 0.0272216796875, 0.130859375]\n",
      "residual[-1][-5:]: [0.6328125, -0.71875, -0.3671875, -2.484375, -4.25]\n",
      "Layer 26\n",
      "hidden_states[-1][-5:]: [2.796875, -4.78125, 3.3125, -0.5625, 2.171875]\n",
      "residual[-1][-5:]: [0.50390625, 0.12109375, -0.54296875, -2.25, -4.28125]\n",
      "Layer 27\n",
      "hidden_states[-1][-5:]: [-51.5, 56.5, -26.375, 9.875, 27.625]\n",
      "residual[-1][-5:]: [2.734375, -3.984375, 2.671875, -2.984375, -2.609375]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-3.09375, 3.28125, -1.4609375, 0.443359375, 1.5859375]\n",
      "residual[-1][-5:]: [-48.75, 52.5, -23.75, 6.875, 25.0]\n",
      "INFO 06-03 14:04:55 [worker.py:287] Memory profiling takes 0.54 seconds\n",
      "INFO 06-03 14:04:55 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 06-03 14:04:55 [worker.py:287] model weights take 1.12GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.44GiB; the rest of the memory reserved for KV Cache is 68.47GiB.\n",
      "INFO 06-03 14:04:56 [executor_base.py:112] # cuda blocks: 40067, # CPU blocks: 2340\n",
      "INFO 06-03 14:04:56 [executor_base.py:117] Maximum concurrency for 16384 tokens per request: 39.13x\n",
      "INFO 06-03 14:04:58 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 3.03 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    max_seq_len_to_capture=16384,\n",
    "    max_model_len=16384,\n",
    "    quantization=None,\n",
    "    enforce_eager=True,\n",
    "    disable_async_output_proc=True,\n",
    "    download_dir=\"/alloc\",\n",
    "    dtype=\"bfloat16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 17.30it/s, est. speed input: 69.35 toks/s, output: 17.33 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [0.025634765625, -0.036376953125, -0.05810546875, -0.010986328125, 0.0341796875]\n",
      "residual[-1][-5:]: [-0.02294921875, 0.2109375, 0.019775390625, 0.09765625, 0.06298828125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.2236328125, -0.08935546875, -0.022705078125, -0.0296630859375, 0.01373291015625]\n",
      "residual[-1][-5:]: [-0.0478515625, 0.0078125, 0.2001953125, 0.111328125, 0.0654296875]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.001953125, 0.255859375, -0.306640625, 0.11962890625, 0.197265625]\n",
      "residual[-1][-5:]: [0.05126953125, -0.0771484375, 0.3046875, -0.009765625, 0.248046875]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.1259765625, -0.07373046875, -0.2021484375, 0.212890625, 0.1845703125]\n",
      "residual[-1][-5:]: [0.0634765625, 0.29296875, 0.126953125, 0.0810546875, 0.2177734375]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.0196533203125, 0.1572265625, -0.18359375, 0.2333984375, -0.08544921875]\n",
      "residual[-1][-5:]: [0.3515625, 0.1240234375, 0.1083984375, 0.1328125, 0.330078125]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.302734375, 0.06884765625, 0.37890625, -0.11328125, 0.1162109375]\n",
      "residual[-1][-5:]: [0.3359375, 0.416015625, -0.45703125, 0.048828125, 0.2353515625]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.494140625, -0.734375, -0.333984375, -0.9140625, -0.076171875]\n",
      "residual[-1][-5:]: [0.267578125, 0.49609375, -0.1845703125, 0.01513671875, 0.3125]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.064453125, -0.158203125, -0.4921875, -0.1572265625, -0.4375]\n",
      "residual[-1][-5:]: [-0.1513671875, -0.150390625, -0.34765625, -0.703125, 0.4296875]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [-0.10546875, -0.12890625, -0.58984375, 0.2099609375, -0.2001953125]\n",
      "residual[-1][-5:]: [-0.3203125, -0.056640625, -0.515625, -1.1484375, -0.2734375]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.2353515625, 0.2470703125, -0.28125, 0.478515625, 0.0294189453125]\n",
      "residual[-1][-5:]: [-0.53125, -0.09765625, -1.0546875, -1.4453125, -0.33203125]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [-0.361328125, 0.4375, 0.08447265625, -0.05419921875, 0.466796875]\n",
      "residual[-1][-5:]: [-0.57421875, 0.58203125, -1.578125, -0.9609375, -0.1484375]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.2158203125, -0.51953125, 0.27734375, -0.37890625, 0.4296875]\n",
      "residual[-1][-5:]: [-0.7265625, 0.609375, -0.578125, -0.5390625, 0.46484375]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.3203125, -0.01153564453125, 0.240234375, 0.72265625, -0.045166015625]\n",
      "residual[-1][-5:]: [-0.609375, 0.2197265625, -0.4453125, -0.8359375, 0.73828125]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [-0.263671875, 0.71484375, 0.484375, 1.0703125, -0.1083984375]\n",
      "residual[-1][-5:]: [-0.296875, 0.25390625, -0.0498046875, -0.177734375, 0.84765625]\n",
      "Layer 14\n",
      "hidden_states[-1][-5:]: [-0.5, -0.60546875, 0.349609375, -0.298828125, 0.1376953125]\n",
      "residual[-1][-5:]: [-1.015625, 1.0546875, -0.1328125, 0.2890625, 0.98828125]\n",
      "Layer 15\n",
      "hidden_states[-1][-5:]: [0.6796875, 0.39453125, 0.65625, 0.330078125, -0.20703125]\n",
      "residual[-1][-5:]: [-1.578125, 0.890625, 0.404296875, -0.2421875, 1.8671875]\n",
      "Layer 16\n",
      "hidden_states[-1][-5:]: [-0.5625, 0.2216796875, -0.27734375, 0.0439453125, -0.4609375]\n",
      "residual[-1][-5:]: [-0.16796875, 0.2578125, 1.046875, -0.353515625, 2.234375]\n",
      "Layer 17\n",
      "hidden_states[-1][-5:]: [-0.53515625, -0.6484375, 0.1513671875, 1.1484375, -1.4296875]\n",
      "residual[-1][-5:]: [-0.7890625, 1.421875, 0.78125, -1.140625, 1.5859375]\n",
      "Layer 18\n",
      "hidden_states[-1][-5:]: [0.93359375, 0.359375, -0.2734375, -0.126953125, -1.3046875]\n",
      "residual[-1][-5:]: [-1.0625, 2.28125, 0.5546875, -0.26171875, 0.33203125]\n",
      "Layer 19\n",
      "hidden_states[-1][-5:]: [0.359375, -2.53125, -0.365234375, -1.421875, 1.8359375]\n",
      "residual[-1][-5:]: [0.39453125, 3.8125, -1.5078125, 0.158203125, -2.53125]\n",
      "Layer 20\n",
      "hidden_states[-1][-5:]: [-2.546875, 3.0625, 0.1337890625, 2.65625, 1.796875]\n",
      "residual[-1][-5:]: [-0.10546875, 1.9296875, -3.5625, -3.390625, -1.65625]\n",
      "Layer 21\n",
      "hidden_states[-1][-5:]: [0.7890625, 0.0189208984375, -0.48828125, -0.328125, 0.58203125]\n",
      "residual[-1][-5:]: [-2.640625, 4.28125, -4.53125, -0.02734375, 0.86328125]\n",
      "Layer 22\n",
      "hidden_states[-1][-5:]: [-3.484375, 1.7890625, 2.171875, -0.1328125, 2.65625]\n",
      "residual[-1][-5:]: [-1.984375, 3.03125, -3.9375, 0.044921875, 0.4921875]\n",
      "Layer 23\n",
      "hidden_states[-1][-5:]: [-3.625, 1.0078125, 1.125, -1.8359375, -0.1904296875]\n",
      "residual[-1][-5:]: [-3.96875, 5.4375, -3.71875, 0.65625, 3.4375]\n",
      "Layer 24\n",
      "hidden_states[-1][-5:]: [0.01092529296875, -3.265625, 0.2490234375, 0.62109375, -2.8125]\n",
      "residual[-1][-5:]: [-7.5, 4.6875, -3.25, -6.25, 4.0625]\n",
      "Layer 25\n",
      "hidden_states[-1][-5:]: [-3.578125, -0.1328125, -1.5625, 1.1171875, 0.53515625]\n",
      "residual[-1][-5:]: [-8.5, -0.2578125, -1.8359375, -7.71875, -2.6875]\n",
      "Layer 26\n",
      "hidden_states[-1][-5:]: [3.59375, 4.34375, -1.3984375, 5.34375, -1.15625]\n",
      "residual[-1][-5:]: [-11.375, -0.62109375, -3.6875, -5.90625, -2.125]\n",
      "Layer 27\n",
      "hidden_states[-1][-5:]: [0.73828125, 0.08544921875, -1.734375, -2.078125, 0.7578125]\n",
      "residual[-1][-5:]: [-8.125, 6.4375, -5.75, -0.796875, -4.625]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-1.25, 1.09375, -1.234375, -0.49609375, -0.65625]\n",
      "residual[-1][-5:]: [-7.375, 6.53125, -7.5, -2.875, -3.875]\n",
      " Welcome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=1,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    seed=42,\n",
    ")\n",
    "request_outputs = llm.generate(\"Hello, world!\", sampling_params)\n",
    "print(request_outputs[0].outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
