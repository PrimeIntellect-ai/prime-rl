{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/prime-rl/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:08 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 14:25:09,641\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-03 14:25:12 [INFER] [INFO] Created node (ee1aa49a4459dfe813a3cf6eb882041230c7b2558469de81f87c9bf23bf10a03)\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:12Z \u001b[1m\u001b[31mERROR\u001b[0m iroh::discovery::pkarr\u001b[90m]\u001b[0m pkarr_publish; me=ee1aa49a44\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:12Z \u001b[1m\u001b[31mERROR\u001b[0m tracing::span\u001b[90m]\u001b[0m magicsock;\n",
      "06-03 14:25:12 [INFER] [INFO] Setting up outgoing connection to ff87a0b0a3c7c0ce827e9cada5ff79e75a44a0633bfcb5b50f99307ddb26b337\n",
      "\u001b[90m[\u001b[0m2025-06-03T14:25:12Z \u001b[1m\u001b[31mERROR\u001b[0m iroh::discovery\u001b[90m]\u001b[0m discovery; me=ee1aa49a44 node=ff87a0b0a3\n",
      "06-03 14:25:15 [INFER] [INFO] Outgoing connection to ff87a0b0a3c7c0ce827e9cada5ff79e75a44a0633bfcb5b50f99307ddb26b337 successful!\n",
      "06-03 14:25:15 [INFER] [INFO] Waiting for incoming connection...\n",
      "06-03 14:25:15 [INFER] [INFO] All connections successful!\n",
      "06-03 14:25:15 [INFER] [INFO] Patching model init for pp.rank=0 in pp.world_size=2\n"
     ]
    }
   ],
   "source": [
    "from src.zeroband.inference.pipeline import PipelineConfig, patch_model_load, setup_comm, setup_hooks\n",
    "\n",
    "config = PipelineConfig(\n",
    "    rank=0,\n",
    "    world_size=2,\n",
    "    iroh_seed=0,\n",
    "    iroh_peer_id=\"ff87a0b0a3c7c0ce827e9cada5ff79e75a44a0633bfcb5b50f99307ddb26b337\",\n",
    "    connection_num_retries=3,\n",
    ")\n",
    "\n",
    "node = setup_comm(config)\n",
    "patch_model_load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:22 [config.py:717] This model supports multiple tasks: {'generate', 'embed', 'reward', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "WARNING 06-03 14:25:22 [arg_utils.py:1658] --disable-async-output-proc is not supported by the V1 Engine. Falling back to V0. We recommend to remove --disable-async-output-proc from your config in favor of the V1 Engine.\n",
      "INFO 06-03 14:25:23 [config.py:1770] Defaulting to use mp for distributed inference\n",
      "INFO 06-03 14:25:23 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='Qwen/Qwen3-0.6B', speculative_config=None, tokenizer='Qwen/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir='/alloc', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen3-0.6B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
      "WARNING 06-03 14:25:23 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 104 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:23 [multiproc_worker_utils.py:225] Worker ready; awaiting tasks\n",
      "INFO 06-03 14:25:23 [cuda.py:292] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:23 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 06-03 14:25:28 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:28 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 06-03 14:25:28 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:28 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 06-03 14:25:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 06-03 14:25:30 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_4e3f3a27'), local_subscribe_addr='ipc:///tmp/1861d13a-aaac-4ffb-9a5d-72c96f0aec78', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 06-03 14:25:30 [parallel_state.py:1006] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [parallel_state.py:1006] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "INFO 06-03 14:25:30 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "INFO 06-03 14:25:30 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n",
      "INFO 06-03 14:25:30 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:30 [loader.py:458] Loading weights took 0.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:30 [loader.py:458] Loading weights took 0.10 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:31 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.376879 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:25:31 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.279736 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.044921875, -0.0185546875, 0.06103515625, -0.0830078125, -0.0274658203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.1123046875, 0.11474609375, 0.0732421875, 0.1279296875, -0.0001220703125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 1\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.021728515625, 0.1611328125, -0.212890625, 0.1484375, -0.263671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.0078125, -0.08935546875, -0.0595703125, -0.287109375, -0.15625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.328125, -0.0244140625, 0.828125, -2.15625, -3.5625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.291015625, -0.515625, -0.8671875, -0.59375, 0.158203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 3\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0001678466796875, 0.0018768310546875, 0.0021209716796875, -0.00011444091796875, -0.007049560546875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.11279296875, -0.625, 0.0166015625, -2.78125, -3.453125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 4\n",
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [-0.044921875, -0.0185546875, 0.06103515625, -0.0830078125, -0.0274658203125]\n",
      "residual[-1][-5:]: [0.1123046875, 0.11474609375, 0.0732421875, 0.1279296875, -0.0001220703125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.021728515625, 0.1611328125, -0.212890625, 0.1484375, -0.263671875]\n",
      "residual[-1][-5:]: [-0.0078125, -0.08935546875, -0.0595703125, -0.287109375, -0.15625]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.328125, -0.0244140625, 0.828125, -2.15625, -3.5625]\n",
      "residual[-1][-5:]: [-0.291015625, -0.515625, -0.8671875, -0.59375, 0.158203125]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.0001678466796875, 0.0018768310546875, 0.0021209716796875, -0.00011444091796875, -0.007049560546875]\n",
      "residual[-1][-5:]: [0.11279296875, -0.625, 0.0166015625, -2.78125, -3.453125]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.0020904541015625, 0.0050048828125, 0.0027008056640625, -0.000667572021484375, -0.001983642578125]\n",
      "residual[-1][-5:]: [0.15234375, -0.61328125, 0.0130615234375, -2.796875, -3.484375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.0020904541015625, 0.0050048828125, 0.0027008056640625, -0.000667572021484375, -0.001983642578125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.15234375, -0.61328125, 0.0130615234375, -2.796875, -3.484375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.002593994140625, 0.00689697265625, 0.002410888671875, -0.00543212890625, -0.00518798828125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.236328125, -0.62109375, -0.0108642578125, -2.765625, -3.59375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 6\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.003173828125, 0.00555419921875, -0.000457763671875, -7.2479248046875e-05, -0.002044677734375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.2412109375, -0.5859375, -0.12890625, -2.765625, -3.65625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 7\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.006500244140625, -0.004730224609375, 0.002288818359375, 0.01495361328125, 0.005126953125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.37890625, -0.6484375, -0.0576171875, -2.734375, -3.796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 8\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.00031280517578125, -0.002960205078125, -0.0015716552734375, -0.000415802001953125, 0.0026397705078125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.373046875, -0.640625, -0.006591796875, -2.859375, -3.90625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 9\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.003082275390625, 0.0072021484375, 0.0087890625, 0.00531005859375, 0.00052642822265625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.2109375, -0.53515625, -0.12451171875, -2.890625, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 10\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.00982666015625, 0.00750732421875, 0.01031494140625, 0.0111083984375, -0.0006561279296875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.3515625, -0.2578125, -0.119140625, -2.65625, -4.0625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 11\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0015411376953125, -0.0021209716796875, -0.00286865234375, -0.0009918212890625, 0.00213623046875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.40234375, -0.298828125, -0.287109375, -2.59375, -4.28125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 12\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0028076171875, -0.00537109375, 0.006805419921875, 0.001434326171875, -0.0023193359375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.5078125, -0.25, -0.3125, -2.453125, -4.21875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 13\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.004791259765625, -0.00762939453125, 0.0078125, 0.00799560546875, 0.00360107421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.6484375, -0.283203125, -0.361328125, -2.5, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0133056640625, -0.005859375, -0.00701904296875, -0.051513671875, -0.08203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.65234375, -0.291015625, -0.353515625, -2.484375, -4.03125]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.002593994140625, 0.00689697265625, 0.002410888671875, -0.00543212890625, -0.00518798828125]\n",
      "residual[-1][-5:]: [0.236328125, -0.62109375, -0.0108642578125, -2.765625, -3.59375]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.003173828125, 0.00555419921875, -0.000457763671875, -7.2479248046875e-05, -0.002044677734375]\n",
      "residual[-1][-5:]: [0.2412109375, -0.5859375, -0.12890625, -2.765625, -3.65625]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.006500244140625, -0.004730224609375, 0.002288818359375, 0.01495361328125, 0.005126953125]\n",
      "residual[-1][-5:]: [0.37890625, -0.6484375, -0.0576171875, -2.734375, -3.796875]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [0.00031280517578125, -0.002960205078125, -0.0015716552734375, -0.000415802001953125, 0.0026397705078125]\n",
      "residual[-1][-5:]: [0.373046875, -0.640625, -0.006591796875, -2.859375, -3.90625]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.003082275390625, 0.0072021484375, 0.0087890625, 0.00531005859375, 0.00052642822265625]\n",
      "residual[-1][-5:]: [0.2109375, -0.53515625, -0.12451171875, -2.890625, -4.03125]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [0.00982666015625, 0.00750732421875, 0.01031494140625, 0.0111083984375, -0.0006561279296875]\n",
      "residual[-1][-5:]: [0.3515625, -0.2578125, -0.119140625, -2.65625, -4.0625]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.0015411376953125, -0.0021209716796875, -0.00286865234375, -0.0009918212890625, 0.00213623046875]\n",
      "residual[-1][-5:]: [0.40234375, -0.298828125, -0.287109375, -2.59375, -4.28125]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.0028076171875, -0.00537109375, 0.006805419921875, 0.001434326171875, -0.0023193359375]\n",
      "residual[-1][-5:]: [0.5078125, -0.25, -0.3125, -2.453125, -4.21875]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [0.004791259765625, -0.00762939453125, 0.0078125, 0.00799560546875, 0.00360107421875]\n",
      "residual[-1][-5:]: [0.6484375, -0.283203125, -0.361328125, -2.5, -4.03125]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [0.0133056640625, -0.005859375, -0.00701904296875, -0.051513671875, -0.08203125]\n",
      "residual[-1][-5:]: [0.65234375, -0.291015625, -0.353515625, -2.484375, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] Memory profiling takes 2.10 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m INFO 06-03 14:25:33 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.57GiB; PyTorch activation peak memory takes 0.33GiB; the rest of the memory reserved for KV Cache is 68.93GiB.\n",
      "INFO 06-03 14:25:33 [worker.py:287] Memory profiling takes 2.15 seconds\n",
      "INFO 06-03 14:25:33 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 06-03 14:25:33 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.82GiB; PyTorch activation peak memory takes 1.44GiB; the rest of the memory reserved for KV Cache is 67.56GiB.\n",
      "INFO 06-03 14:25:33 [executor_base.py:112] # cuda blocks: 79068, # CPU blocks: 4681\n",
      "INFO 06-03 14:25:33 [executor_base.py:117] Maximum concurrency for 16384 tokens per request: 77.21x\n",
      "INFO 06-03 14:25:36 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 5.20 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    tensor_parallel_size=2,\n",
    "    max_seq_len_to_capture=16384,\n",
    "    max_model_len=16384,\n",
    "    quantization=None,\n",
    "    enforce_eager=True,\n",
    "    disable_async_output_proc=True,\n",
    "    download_dir=\"/alloc\",\n",
    "    dtype=\"bfloat16\")\n",
    "\n",
    "setup_hooks(config, llm, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0255126953125, -0.0361328125, -0.057861328125, -0.0111083984375, 0.0341796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.0234375, 0.2109375, 0.01953125, 0.09765625, 0.06298828125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 1\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.2216796875, -0.08544921875, -0.022705078125, -0.029541015625, 0.01611328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.04931640625, 0.005859375, 0.2001953125, 0.11181640625, 0.06591796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.0009765625, 0.25390625, -0.30859375, 0.12109375, 0.1982421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.0478515625, -0.07373046875, 0.3046875, -0.009765625, 0.2490234375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 3\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.12890625, -0.0693359375, -0.2001953125, 0.2109375, 0.18359375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.057861328125, 0.2890625, 0.1240234375, 0.08544921875, 0.2236328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 4\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.018798828125, 0.1533203125, -0.181640625, 0.236328125, -0.0888671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.3515625, 0.12109375, 0.109375, 0.1337890625, 0.33203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.3046875, 0.0703125, 0.37890625, -0.12109375, 0.1259765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.33984375, 0.408203125, -0.451171875, 0.060546875, 0.2373046875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 6\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.48828125, -0.71875, -0.3515625, -0.90234375, -0.07421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [0.26171875, 0.484375, -0.177734375, 0.01611328125, 0.328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 7\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.050048828125, -0.1591796875, -0.482421875, -0.16796875, -0.4375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.1484375, -0.14453125, -0.34375, -0.69921875, 0.44140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 8\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.095703125, -0.111328125, -0.59375, 0.2158203125, -0.19140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.33203125, -0.0576171875, -0.4921875, -1.1484375, -0.263671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 9\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.236328125, 0.240234375, -0.3125, 0.466796875, 0.025390625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.51953125, -0.0751953125, -1.046875, -1.4375, -0.322265625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 10\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.345703125, 0.44140625, 0.060546875, -0.0322265625, 0.486328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.5703125, 0.6015625, -1.6015625, -0.953125, -0.1416015625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 11\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.228515625, -0.53125, 0.28515625, -0.36328125, 0.4375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.69921875, 0.6484375, -0.6015625, -0.51953125, 0.490234375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 12\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [0.30859375, -0.038818359375, 0.263671875, 0.7109375, -0.0849609375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.578125, 0.255859375, -0.4609375, -0.8046875, 0.76953125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m Layer 13\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m hidden_states[-1][-5:]: [-1.3046875, 2.1875, 0.984375, 2.109375, 1.765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=367161)\u001b[0;0m residual[-1][-5:]: [-0.5546875, 0.94140625, 0.4296875, 0.8828125, 0.74609375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [0.0255126953125, -0.0361328125, -0.057861328125, -0.0111083984375, 0.0341796875]\n",
      "residual[-1][-5:]: [-0.0234375, 0.2109375, 0.01953125, 0.09765625, 0.06298828125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.2216796875, -0.08544921875, -0.022705078125, -0.029541015625, 0.01611328125]\n",
      "residual[-1][-5:]: [-0.04931640625, 0.005859375, 0.2001953125, 0.11181640625, 0.06591796875]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.0009765625, 0.25390625, -0.30859375, 0.12109375, 0.1982421875]\n",
      "residual[-1][-5:]: [0.0478515625, -0.07373046875, 0.3046875, -0.009765625, 0.2490234375]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.12890625, -0.0693359375, -0.2001953125, 0.2109375, 0.18359375]\n",
      "residual[-1][-5:]: [0.057861328125, 0.2890625, 0.1240234375, 0.08544921875, 0.2236328125]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.018798828125, 0.1533203125, -0.181640625, 0.236328125, -0.0888671875]\n",
      "residual[-1][-5:]: [0.3515625, 0.12109375, 0.109375, 0.1337890625, 0.33203125]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.3046875, 0.0703125, 0.37890625, -0.12109375, 0.1259765625]\n",
      "residual[-1][-5:]: [0.33984375, 0.408203125, -0.451171875, 0.060546875, 0.2373046875]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.48828125, -0.71875, -0.3515625, -0.90234375, -0.07421875]\n",
      "residual[-1][-5:]: [0.26171875, 0.484375, -0.177734375, 0.01611328125, 0.328125]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.050048828125, -0.1591796875, -0.482421875, -0.16796875, -0.4375]\n",
      "residual[-1][-5:]: [-0.1484375, -0.14453125, -0.34375, -0.69921875, 0.44140625]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [-0.095703125, -0.111328125, -0.59375, 0.2158203125, -0.19140625]\n",
      "residual[-1][-5:]: [-0.33203125, -0.0576171875, -0.4921875, -1.1484375, -0.263671875]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.236328125, 0.240234375, -0.3125, 0.466796875, 0.025390625]\n",
      "residual[-1][-5:]: [-0.51953125, -0.0751953125, -1.046875, -1.4375, -0.322265625]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [-0.345703125, 0.44140625, 0.060546875, -0.0322265625, 0.486328125]\n",
      "residual[-1][-5:]: [-0.5703125, 0.6015625, -1.6015625, -0.953125, -0.1416015625]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.228515625, -0.53125, 0.28515625, -0.36328125, 0.4375]\n",
      "residual[-1][-5:]: [-0.69921875, 0.6484375, -0.6015625, -0.51953125, 0.490234375]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.30859375, -0.038818359375, 0.263671875, 0.7109375, -0.0849609375]\n",
      "residual[-1][-5:]: [-0.578125, 0.255859375, -0.4609375, -0.8046875, 0.76953125]\n",
      "Sent hidden_states and residual (torch.Size([4, 1024]), torch.Size([4, 1024])) (16544 bytes)\n",
      "hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "residual[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "residual[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-1.3046875, 2.1875, 0.984375, 2.109375, 1.765625]\n",
      "residual[-1][-5:]: [-0.5546875, 0.94140625, 0.4296875, 0.8828125, 0.74609375]\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "Expected `float`, got `null` - at `$[0][0][0][0][2][...].logprob`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamplingParams\n\u001b[32m      3\u001b[39m sampling_params = SamplingParams(\n\u001b[32m      4\u001b[39m     max_tokens=\u001b[32m1\u001b[39m,\n\u001b[32m      5\u001b[39m     temperature=\u001b[32m0.7\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     seed=\u001b[32m42\u001b[39m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m request_outputs = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, world!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(request_outputs[\u001b[32m0\u001b[39m].outputs[\u001b[32m0\u001b[39m].text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/utils.py:1196\u001b[39m, in \u001b[36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1189\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1191\u001b[39m         warnings.warn(\n\u001b[32m   1192\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1193\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1194\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:473\u001b[39m, in \u001b[36mLLM.generate\u001b[39m\u001b[34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[39m\n\u001b[32m    463\u001b[39m     sampling_params = \u001b[38;5;28mself\u001b[39m.get_default_sampling_params()\n\u001b[32m    465\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_and_add_requests(\n\u001b[32m    466\u001b[39m     prompts=parsed_prompts,\n\u001b[32m    467\u001b[39m     params=sampling_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    470\u001b[39m     guided_options=guided_options_request,\n\u001b[32m    471\u001b[39m     priority=priority)\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine_class.validate_outputs(outputs, RequestOutput)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:1423\u001b[39m, in \u001b[36mLLM._run_engine\u001b[39m\u001b[34m(self, use_tqdm)\u001b[39m\n\u001b[32m   1421\u001b[39m total_out_toks = \u001b[32m0\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_engine.has_unfinished_requests():\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m     step_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[32m   1425\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output.finished:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/engine/llm_engine.py:1412\u001b[39m, in \u001b[36mLLMEngine.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     execute_model_req.async_callback = \u001b[38;5;28mself\u001b[39m.async_callbacks[\n\u001b[32m   1409\u001b[39m         virtual_engine]\n\u001b[32m   1411\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28mself\u001b[39m._skip_scheduling_next_step = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InputProcessingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# The input for this request cannot be processed, so we must\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# abort it. If there are remaining requests in the batch that\u001b[39;00m\n\u001b[32m   1418\u001b[39m     \u001b[38;5;66;03m# have been scheduled, they will be retried on the next step.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/executor/executor_base.py:299\u001b[39m, in \u001b[36mDistributedExecutorBase.execute_model\u001b[39m\u001b[34m(self, execute_model_req)\u001b[39m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mself\u001b[39m.parallel_worker_tasks = \u001b[38;5;28mself\u001b[39m._run_workers(\n\u001b[32m    295\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstart_worker_execution_loop\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    296\u001b[39m         async_run_tensor_parallel_workers_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Only the driver worker returns the sampling results.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m driver_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver_execute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m driver_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m driver_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/executor/mp_distributed_executor.py:144\u001b[39m, in \u001b[36mMultiprocessingDistributedExecutor._driver_execute_model\u001b[39m\u001b[34m(self, execute_model_req)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_driver_execute_model\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m, execute_model_req: Optional[ExecuteModelRequest]\n\u001b[32m    138\u001b[39m ) -> Optional[List[SamplerOutput]]:\n\u001b[32m    139\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run execute_model in the driver worker.\u001b[39;00m\n\u001b[32m    140\u001b[39m \n\u001b[32m    141\u001b[39m \u001b[33;03m    Passing None will cause the driver to stop the model execution\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m    loop running in each of the remote workers.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute_model_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/worker/worker_base.py:420\u001b[39m, in \u001b[36mLocalOrDistributedWorkerBase.execute_model\u001b[39m\u001b[34m(self, execute_model_req)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.observability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    416\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observability_config.collect_model_execute_time):\n\u001b[32m    417\u001b[39m         orig_model_execute_time = intermediate_tensors.tensors.get(\n\u001b[32m    418\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel_execute_time\u001b[39m\u001b[33m\"\u001b[39m, torch.tensor(\u001b[32m0\u001b[39m)).item()\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvirtual_engine\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mintermediate_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m model_execute_time = time.perf_counter() - start_time\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_pp_group().is_last_rank:\n\u001b[32m    431\u001b[39m     \u001b[38;5;66;03m# output is IntermediateTensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/vllm/worker/model_runner.py:1820\u001b[39m, in \u001b[36mModelRunner.execute_model\u001b[39m\u001b[34m(self, model_input, kv_caches, intermediate_tensors, num_steps, **kwargs)\u001b[39m\n\u001b[32m   1817\u001b[39m     model_input.async_callback()\n\u001b[32m   1819\u001b[39m \u001b[38;5;66;03m# Sample the next token.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1820\u001b[39m output: SamplerOutput = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1822\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43msampling_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1823\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1824\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.observability_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1825\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.observability_config.collect_model_forward_time\n\u001b[32m   1826\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1827\u001b[39m     model_forward_end.synchronize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1806\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1804\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1809\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/src/zeroband/inference/pipeline.py:278\u001b[39m, in \u001b[36mrecv_output\u001b[39m\u001b[34m(_, __, output, node, relay)\u001b[39m\n\u001b[32m    276\u001b[39m     node.isend(serialized_output, tag=\u001b[32m0\u001b[39m, latency=\u001b[38;5;28;01mNone\u001b[39;00m).wait()\n\u001b[32m    277\u001b[39m     \u001b[38;5;66;03m# logger.debug(f\"Sent outputs ({len(serialized_output)} bytes)\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m output = \u001b[43mdeserialize_sampler_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prime-rl/src/zeroband/inference/pipeline.py:58\u001b[39m, in \u001b[36mdeserialize_sampler_output\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeserialize_sampler_output\u001b[39m(data: \u001b[38;5;28mbytes\u001b[39m) -> SamplerOutput:\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Safely deserializes a vLLM SamplerOutput object\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmsgspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mSamplerOutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: Expected `float`, got `null` - at `$[0][0][0][0][2][...].logprob`"
     ]
    }
   ],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=1,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    seed=42,\n",
    ")\n",
    "request_outputs = llm.generate(\"Hello, world!\", sampling_params)\n",
    "print(request_outputs[0].outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
