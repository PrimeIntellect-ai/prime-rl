{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/prime-rl/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:10:54 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 14:10:56,562\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-03 14:10:58 [INFER] [INFO] Patching model init for pp.rank=0 in pp.world_size=2\n"
     ]
    }
   ],
   "source": [
    "from src.zeroband.inference.pipeline import PipelineConfig, patch_model_load\n",
    "\n",
    "config = PipelineConfig(\n",
    "    rank=0,\n",
    "    world_size=2,\n",
    "    iroh_seed=None,\n",
    "    iroh_peer_id=None,\n",
    "    connection_num_retries=3,\n",
    ")\n",
    "patch_model_load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:11:05 [config.py:717] This model supports multiple tasks: {'reward', 'score', 'classify', 'embed', 'generate'}. Defaulting to 'generate'.\n",
      "WARNING 06-03 14:11:05 [arg_utils.py:1658] --disable-async-output-proc is not supported by the V1 Engine. Falling back to V0. We recommend to remove --disable-async-output-proc from your config in favor of the V1 Engine.\n",
      "INFO 06-03 14:11:05 [config.py:1770] Defaulting to use mp for distributed inference\n",
      "INFO 06-03 14:11:05 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5.post1) with config: model='Qwen/Qwen3-0.6B', speculative_config=None, tokenizer='Qwen/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir='/alloc', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=Qwen/Qwen3-0.6B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
      "WARNING 06-03 14:11:06 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 104 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:06 [multiproc_worker_utils.py:225] Worker ready; awaiting tasks\n",
      "INFO 06-03 14:11:06 [cuda.py:292] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:06 [cuda.py:292] Using Flash Attention backend.\n",
      "INFO 06-03 14:11:08 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "INFO 06-03 14:11:08 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:08 [utils.py:1055] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:08 [pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 06-03 14:11:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:09 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_1,2.json\n",
      "INFO 06-03 14:11:09 [shm_broadcast.py:266] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_3022bfde'), local_subscribe_addr='ipc:///tmp/9a793060-be19-4799-98c7-d7e94f8a7263', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 06-03 14:11:09 [parallel_state.py:1006] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:09 [parallel_state.py:1006] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1\n",
      "INFO 06-03 14:11:09 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:09 [model_runner.py:1108] Starting to load model Qwen/Qwen3-0.6B...\n",
      "INFO 06-03 14:11:09 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:09 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 06-03 14:11:09 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 14:11:09 [loader.py:458] Loading weights took 0.10 seconds\n",
      "INFO 06-03 14:11:10 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.339777 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:10 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:10 [loader.py:458] Loading weights took 0.10 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:10 [model_runner.py:1140] Model loading took 0.3628 GiB and 0.694652 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.044921875, -0.0185546875, 0.06103515625, -0.0830078125, -0.0274658203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.1123046875, 0.11474609375, 0.0732421875, 0.1279296875, -0.0001220703125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 1\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.021728515625, 0.1611328125, -0.212890625, 0.1484375, -0.263671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.0078125, -0.08935546875, -0.0595703125, -0.287109375, -0.15625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.328125, -0.0244140625, 0.828125, -2.15625, -3.5625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.291015625, -0.515625, -0.8671875, -0.59375, 0.158203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 3\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0001678466796875, 0.0018768310546875, 0.0021209716796875, -0.00011444091796875, -0.007049560546875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.11279296875, -0.625, 0.0166015625, -2.78125, -3.453125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 4\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.0020904541015625, 0.0050048828125, 0.0027008056640625, -0.000667572021484375, -0.001983642578125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.15234375, -0.61328125, 0.0130615234375, -2.796875, -3.484375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.002593994140625, 0.00689697265625, 0.002410888671875, -0.00543212890625, -0.00518798828125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.236328125, -0.62109375, -0.0108642578125, -2.765625, -3.59375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 6Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [-0.044921875, -0.0185546875, 0.06103515625, -0.0830078125, -0.0274658203125]\n",
      "residual[-1][-5:]: [0.1123046875, 0.11474609375, 0.0732421875, 0.1279296875, -0.0001220703125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.021728515625, 0.1611328125, -0.212890625, 0.1484375, -0.263671875]\n",
      "residual[-1][-5:]: [-0.0078125, -0.08935546875, -0.0595703125, -0.287109375, -0.15625]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.328125, -0.0244140625, 0.828125, -2.15625, -3.5625]\n",
      "residual[-1][-5:]: [-0.291015625, -0.515625, -0.8671875, -0.59375, 0.158203125]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.0001678466796875, 0.0018768310546875, 0.0021209716796875, -0.00011444091796875, -0.007049560546875]\n",
      "residual[-1][-5:]: [0.11279296875, -0.625, 0.0166015625, -2.78125, -3.453125]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.0020904541015625, 0.0050048828125, 0.0027008056640625, -0.000667572021484375, -0.001983642578125]\n",
      "residual[-1][-5:]: [0.15234375, -0.61328125, 0.0130615234375, -2.796875, -3.484375]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.002593994140625, 0.00689697265625, 0.002410888671875, -0.00543212890625, -0.00518798828125]\n",
      "residual[-1][-5:]: [0.236328125, -0.62109375, -0.0108642578125, -2.765625, -3.59375]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.003173828125, 0.00555419921875, -0.000457763671875, -7.2479248046875e-05, -0.002044677734375]\n",
      "residual[-1][-5:]: [0.2412109375, -0.5859375, -0.12890625, -2.765625, -3.65625]\n",
      "\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.003173828125, 0.00555419921875, -0.000457763671875, -7.2479248046875e-05, -0.002044677734375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.2412109375, -0.5859375, -0.12890625, -2.765625, -3.65625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 7\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.006500244140625, -0.004730224609375, 0.002288818359375, 0.01495361328125, 0.005126953125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.37890625, -0.6484375, -0.0576171875, -2.734375, -3.796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 8\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.00031280517578125, -0.002960205078125, -0.0015716552734375, -0.000415802001953125, 0.0026397705078125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.373046875, -0.640625, -0.006591796875, -2.859375, -3.90625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 9\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.003082275390625, 0.0072021484375, 0.0087890625, 0.00531005859375, 0.00052642822265625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.2109375, -0.53515625, -0.12451171875, -2.890625, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 10\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.00982666015625, 0.00750732421875, 0.01031494140625, 0.0111083984375, -0.0006561279296875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.3515625, -0.2578125, -0.119140625, -2.65625, -4.0625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 11\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0015411376953125, -0.0021209716796875, -0.00286865234375, -0.0009918212890625, 0.00213623046875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.40234375, -0.298828125, -0.287109375, -2.59375, -4.28125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 12\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0028076171875, -0.00537109375, 0.006805419921875, 0.001434326171875, -0.0023193359375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.5078125, -0.25, -0.3125, -2.453125, -4.21875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 13\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.004791259765625, -0.00762939453125, 0.0078125, 0.00799560546875, 0.00360107421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.6484375, -0.283203125, -0.361328125, -2.5, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0133056640625, -0.005859375, -0.00701904296875, -0.051513671875, -0.08203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.65234375, -0.291015625, -0.353515625, -2.484375, -4.03125]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.006500244140625, -0.004730224609375, 0.002288818359375, 0.01495361328125, 0.005126953125]\n",
      "residual[-1][-5:]: [0.37890625, -0.6484375, -0.0576171875, -2.734375, -3.796875]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [0.00031280517578125, -0.002960205078125, -0.0015716552734375, -0.000415802001953125, 0.0026397705078125]\n",
      "residual[-1][-5:]: [0.373046875, -0.640625, -0.006591796875, -2.859375, -3.90625]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.003082275390625, 0.0072021484375, 0.0087890625, 0.00531005859375, 0.00052642822265625]\n",
      "residual[-1][-5:]: [0.2109375, -0.53515625, -0.12451171875, -2.890625, -4.03125]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [0.00982666015625, 0.00750732421875, 0.01031494140625, 0.0111083984375, -0.0006561279296875]\n",
      "residual[-1][-5:]: [0.3515625, -0.2578125, -0.119140625, -2.65625, -4.0625]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.0015411376953125, -0.0021209716796875, -0.00286865234375, -0.0009918212890625, 0.00213623046875]\n",
      "residual[-1][-5:]: [0.40234375, -0.298828125, -0.287109375, -2.59375, -4.28125]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.0028076171875, -0.00537109375, 0.006805419921875, 0.001434326171875, -0.0023193359375]\n",
      "residual[-1][-5:]: [0.5078125, -0.25, -0.3125, -2.453125, -4.21875]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [0.004791259765625, -0.00762939453125, 0.0078125, 0.00799560546875, 0.00360107421875]\n",
      "residual[-1][-5:]: [0.6484375, -0.283203125, -0.361328125, -2.5, -4.03125]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [0.0133056640625, -0.005859375, -0.00701904296875, -0.051513671875, -0.08203125]\n",
      "residual[-1][-5:]: [0.65234375, -0.291015625, -0.353515625, -2.484375, -4.03125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:12 [worker.py:287] Memory profiling takes 1.75 seconds\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:12 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m INFO 06-03 14:11:12 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.57GiB; PyTorch activation peak memory takes 0.33GiB; the rest of the memory reserved for KV Cache is 68.93GiB.\n",
      "INFO 06-03 14:11:12 [worker.py:287] Memory profiling takes 1.79 seconds\n",
      "INFO 06-03 14:11:12 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 06-03 14:11:12 [worker.py:287] model weights take 0.36GiB; non_torch_memory takes 1.82GiB; PyTorch activation peak memory takes 1.44GiB; the rest of the memory reserved for KV Cache is 67.56GiB.\n",
      "INFO 06-03 14:11:12 [executor_base.py:112] # cuda blocks: 79068, # CPU blocks: 4681\n",
      "INFO 06-03 14:11:12 [executor_base.py:117] Maximum concurrency for 16384 tokens per request: 77.21x\n",
      "INFO 06-03 14:11:15 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 4.93 seconds\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=\"Qwen/Qwen3-0.6B\",\n",
    "    tensor_parallel_size=2,\n",
    "    max_seq_len_to_capture=16384,\n",
    "    max_model_len=16384,\n",
    "    quantization=None,\n",
    "    enforce_eager=True,\n",
    "    disable_async_output_proc=True,\n",
    "    download_dir=\"/alloc\",\n",
    "    dtype=\"bfloat16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, est. speed input: 19.10 toks/s, output: 4.77 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Input\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual is None\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 0\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0255126953125, -0.0361328125, -0.057861328125, -0.0111083984375, 0.0341796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.0234375, 0.2109375, 0.01953125, 0.09765625, 0.06298828125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 1\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.2216796875, -0.08544921875, -0.022705078125, -0.029541015625, 0.01611328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.04931640625, 0.005859375, 0.2001953125, 0.11181640625, 0.06591796875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.0009765625, 0.25390625, -0.30859375, 0.12109375, 0.1982421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.0478515625, -0.07373046875, 0.3046875, -0.009765625, 0.2490234375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 3\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.12890625, -0.0693359375, -0.2001953125, 0.2109375, 0.18359375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.057861328125, 0.2890625, 0.1240234375, 0.08544921875, 0.2236328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 4\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.018798828125, 0.1533203125, -0.181640625, 0.236328125, -0.0888671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.3515625, 0.12109375, 0.109375, 0.1337890625, 0.33203125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.3046875, 0.0703125, 0.37890625, -0.12109375, 0.1259765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.33984375, 0.408203125, -0.451171875, 0.060546875, 0.2373046875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 6\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.48828125, -0.71875, -0.3515625, -0.90234375, -0.07421875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [0.26171875, 0.484375, -0.177734375, 0.01611328125, 0.328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 7\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.050048828125, -0.1591796875, -0.482421875, -0.16796875, -0.4375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.1484375, -0.14453125, -0.34375, -0.69921875, 0.44140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 8\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.095703125, -0.111328125, -0.59375, 0.2158203125, -0.19140625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.33203125, -0.0576171875, -0.4921875, -1.1484375, -0.263671875]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 9\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.236328125, 0.240234375, -0.3125, 0.466796875, 0.025390625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.51953125, -0.0751953125, -1.046875, -1.4375, -0.322265625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 10\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.345703125, 0.44140625, 0.060546875, -0.0322265625, 0.486328125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.5703125, 0.6015625, -1.6015625, -0.953125, -0.1416015625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 11\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.228515625, -0.53125, 0.28515625, -0.36328125, 0.4375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.69921875, 0.6484375, -0.6015625, -0.51953125, 0.490234375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 12\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [0.30859375, -0.038818359375, 0.263671875, 0.7109375, -0.0849609375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.578125, 0.255859375, -0.4609375, -0.8046875, 0.76953125]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m Layer 13\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m After norm\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m hidden_states[-1][-5:]: [-1.3046875, 2.1875, 0.984375, 2.109375, 1.765625]\n",
      "\u001b[1;36m(VllmWorkerProcess pid=357794)\u001b[0;0m residual[-1][-5:]: [-0.5546875, 0.94140625, 0.4296875, 0.8828125, 0.74609375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "hidden_states[-1][-5:]: [0.0546875, 0.00909423828125, 0.011962890625, -0.01055908203125, 0.0159912109375]\n",
      "residual is None\n",
      "Layer 0\n",
      "hidden_states[-1][-5:]: [0.0255126953125, -0.0361328125, -0.057861328125, -0.0111083984375, 0.0341796875]\n",
      "residual[-1][-5:]: [-0.0234375, 0.2109375, 0.01953125, 0.09765625, 0.06298828125]\n",
      "Layer 1\n",
      "hidden_states[-1][-5:]: [0.2216796875, -0.08544921875, -0.022705078125, -0.029541015625, 0.01611328125]\n",
      "residual[-1][-5:]: [-0.04931640625, 0.005859375, 0.2001953125, 0.11181640625, 0.06591796875]\n",
      "Layer 2\n",
      "hidden_states[-1][-5:]: [0.0009765625, 0.25390625, -0.30859375, 0.12109375, 0.1982421875]\n",
      "residual[-1][-5:]: [0.0478515625, -0.07373046875, 0.3046875, -0.009765625, 0.2490234375]\n",
      "Layer 3\n",
      "hidden_states[-1][-5:]: [0.12890625, -0.0693359375, -0.2001953125, 0.2109375, 0.18359375]\n",
      "residual[-1][-5:]: [0.057861328125, 0.2890625, 0.1240234375, 0.08544921875, 0.2236328125]\n",
      "Layer 4\n",
      "hidden_states[-1][-5:]: [-0.018798828125, 0.1533203125, -0.181640625, 0.236328125, -0.0888671875]\n",
      "residual[-1][-5:]: [0.3515625, 0.12109375, 0.109375, 0.1337890625, 0.33203125]\n",
      "Layer 5\n",
      "hidden_states[-1][-5:]: [-0.3046875, 0.0703125, 0.37890625, -0.12109375, 0.1259765625]\n",
      "residual[-1][-5:]: [0.33984375, 0.408203125, -0.451171875, 0.060546875, 0.2373046875]\n",
      "Layer 6\n",
      "hidden_states[-1][-5:]: [-0.48828125, -0.71875, -0.3515625, -0.90234375, -0.07421875]\n",
      "residual[-1][-5:]: [0.26171875, 0.484375, -0.177734375, 0.01611328125, 0.328125]\n",
      "Layer 7\n",
      "hidden_states[-1][-5:]: [0.050048828125, -0.1591796875, -0.482421875, -0.16796875, -0.4375]\n",
      "residual[-1][-5:]: [-0.1484375, -0.14453125, -0.34375, -0.69921875, 0.44140625]\n",
      "Layer 8\n",
      "hidden_states[-1][-5:]: [-0.095703125, -0.111328125, -0.59375, 0.2158203125, -0.19140625]\n",
      "residual[-1][-5:]: [-0.33203125, -0.0576171875, -0.4921875, -1.1484375, -0.263671875]\n",
      "Layer 9\n",
      "hidden_states[-1][-5:]: [0.236328125, 0.240234375, -0.3125, 0.466796875, 0.025390625]\n",
      "residual[-1][-5:]: [-0.51953125, -0.0751953125, -1.046875, -1.4375, -0.322265625]\n",
      "Layer 10\n",
      "hidden_states[-1][-5:]: [-0.345703125, 0.44140625, 0.060546875, -0.0322265625, 0.486328125]\n",
      "residual[-1][-5:]: [-0.5703125, 0.6015625, -1.6015625, -0.953125, -0.1416015625]\n",
      "Layer 11\n",
      "hidden_states[-1][-5:]: [0.228515625, -0.53125, 0.28515625, -0.36328125, 0.4375]\n",
      "residual[-1][-5:]: [-0.69921875, 0.6484375, -0.6015625, -0.51953125, 0.490234375]\n",
      "Layer 12\n",
      "hidden_states[-1][-5:]: [0.30859375, -0.038818359375, 0.263671875, 0.7109375, -0.0849609375]\n",
      "residual[-1][-5:]: [-0.578125, 0.255859375, -0.4609375, -0.8046875, 0.76953125]\n",
      "Layer 13\n",
      "hidden_states[-1][-5:]: [-0.279296875, 0.67578125, 0.46875, 1.046875, -0.09765625]\n",
      "residual[-1][-5:]: [-0.275390625, 0.265625, -0.0380859375, -0.166015625, 0.84375]\n",
      "After norm\n",
      "hidden_states[-1][-5:]: [-1.3046875, 2.1875, 0.984375, 2.109375, 1.765625]\n",
      "residual[-1][-5:]: [-0.5546875, 0.94140625, 0.4296875, 0.8828125, 0.74609375]\n",
      " import\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    max_tokens=1,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    seed=42,\n",
    ")\n",
    "request_outputs = llm.generate(\"Hello, world!\", sampling_params)\n",
    "print(request_outputs[0].outputs[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
