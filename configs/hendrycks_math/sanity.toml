inference_gpu_ids = [0]
trainer_gpu_ids = [1]

max_steps = 3000
seq_len = 8192

[wandb]
project = "hendrycks-math-debug"
name = "hendrycks-math-sanity"

[model]
name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"

[orchestrator]
batch_size = 512
rollouts_per_example = 8

[[orchestrator.env]]
id = "primeintellect/math-env"
args = { dataset_name = "mikasenghaas/Sanity-Test-R1D-1.5B", dataset_subset = "default" }
name = "hendrycks-math"

[orchestrator.eval]
interval = 50

[[orchestrator.eval.env]]
id = "primeintellect/aime2024"
name = "aime2024"
rollouts_per_example = 32

[trainer.model]
name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"

[trainer.model.ac]

[trainer.model.compile]

[inference.model]
max_model_len = 8192

[log]
level = "debug"