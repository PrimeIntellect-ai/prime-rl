inference_gpu_ids = [0]
trainer_gpu_ids = [1]

max_steps = 500

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[wandb]
project = "wiki-search-debug"
name = "wiki-search-4b"

[trainer.optim]
lr = 1e-5
weight_decay = 0.0

[trainer.model.experimental.lora]
rank = 8
alpha = 32

[trainer.weight_broadcast]
adapter_only = true

[orchestrator]
batch_size = 512
rollouts_per_example = 16
seq_len = 4096
lora_name = "r8-32-1e-5"
oversampling_factor = 2.0

[orchestrator.sampling]
max_tokens = 512

[[orchestrator.env]]
id = "primeintellect/wiki-search"
name = "wiki-search"

[orchestrator.buffer]
online_difficulty_filtering = true

[inference]
enable_lora = true

[inference.model]
enable_auto_tool_choice = true
tool_call_parser = "hermes"
