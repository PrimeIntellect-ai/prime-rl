max_steps = 10

[ckpt]

[model]
name = "PrimeIntellect/Qwen3-0.6B"

[model.lora]
rank = 8

[ckpt.weights]
save_adapter_separately = true

[optim]
lr = 1e-4

[data]
name = "PrimeIntellect/Reverse-Text-SFT"
batch_size = 4
seq_len = 1024
