inference_gpu_ids = [0,1,2,3,4,5]
trainer_gpu_ids = [6,7]

max_steps = 100

[model]
name = "PrimeIntellect/Qwen3-1.7B"

[orchestrator]
batch_size = 512
rollouts_per_example = 16
seq_len = 2048

[orchestrator.sampling]
max_tokens = 512

[[orchestrator.env]]
id = "primeintellect/alphabet-sort"
name = "alphabet-sort"
args = { min_turns = 2, max_turns = 2 }

[trainer]

[inference.parallel]
dp = 6
