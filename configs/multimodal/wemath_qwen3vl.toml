# WeMath + Qwen3-VL-4B-Instruct training configuration

trainer_gpu_ids = [0]
inference_gpu_ids = [1]

max_steps = 500
seq_len = 4096  # VLM needs longer context for image tokens

[wandb]
project = "wemath-qwen3vl"
name = "wemath-qwen3vl-4b"

[model]
name = "Qwen/Qwen3-VL-4B-Instruct"

[orchestrator]
batch_size = 256  # Smaller batch due to larger sequence length
rollouts_per_example = 8

[orchestrator.sampling]
max_tokens = 2048

[[orchestrator.env]]
id = "wemath"
name = "wemath-standard"
args = { configs = ["wemath_standard"], format = "qwen3vl", image_max_size = 512 }

[orchestrator.buffer]
easy_threshold = 1.0
hard_threshold = 0.0

[orchestrator.val]
interval = 5
num_examples = 64

[orchestrator.eval]
interval = 10

[orchestrator.eval.sampling]
max_tokens = 2048

[[orchestrator.eval.env]]
id = "wemath"
name = "wemath-eval"
args = { configs = ["wemath_standard"], format = "qwen3vl", image_max_size = 512, eval_max_examples = 100 }
num_examples = 100
rollouts_per_example = 4

[trainer]  # Default trainer config

[inference]  # Default inference config
