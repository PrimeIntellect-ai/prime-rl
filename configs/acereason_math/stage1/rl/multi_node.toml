max_steps = 500

num_training_nodes = 1
num_inference_nodes = 3

[model]
name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

[ckpt]
interval = 100


[wandb]

## trainer

[trainer.model.ac]

[trainer.optim]
lr = 1e-6

### inference
[inference.parallel]
tp = 4

### orchestrator
[orchestrator]
batch_size = 1024
seq_len = 8192
rollouts_per_example = 8
mask_truncated_completions = false

[orchestrator.sampling]
temperature = 0.6
max_tokens = 8192


[[orchestrator.env]]
id = "acereason-math"

[orchestratorwandb.log_extras]
interval = 50

[orchestrator.eval]
interval = 50

[[orchestrator.eval.env]]
id = "math500"
rollouts_per_example = 1

[[orchestrator.eval.env]]
id = "aime2024"
rollouts_per_example = 32

[[orchestrator.eval.env]]
id = "aime2025"
rollouts_per_example = 32
