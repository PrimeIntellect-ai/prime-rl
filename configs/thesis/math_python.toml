inference_gpu_ids = [0,1,2,3]
trainer_gpu_ids = [4,5,6,7]

max_steps = 300
seq_len = 16384

[wandb]
project = "mika-thesis"
name = "math-python"

[model]
name = "Qwen/Qwen3-4B-Thinking-2507"

[weight_broadcast]
type = "nccl"

[orchestrator]
batch_size = 512
rollouts_per_example = 16
max_concurrent = 128

[orchestrator.sampling]
temperature = 1.1

[[orchestrator.env]]
id = "math-env"
args = { python_tool = true, sandbox_client_max_workers = 128, max_startup_wait_seconds = 180, sandbox_labels = ["math-env", "mika"] }

[trainer.model.compile]

[trainer.model.ac]

[trainer.optim]
type = "sgd"

[inference.parallel]
tp = 4

[inference.model]
enable_auto_tool_choice = true
tool_call_parser = "hermes"

[log]
level = "debug"