inference_gpu_ids = [0,1,2,3,4,5]
trainer_gpu_ids = [6,7]

max_steps = 500
seq_len = 8192

[wandb]
project = "mika-thesis"
name = "wiki-search"

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[orchestrator]
batch_size = 1024
rollouts_per_example = 16
oversampling_factor = 1.5
max_concurrent = 256

[orchestrator.buffer]
online_difficulty_filtering = true

[orchestrator.sampling]
max_tokens = 8192

[[orchestrator.env]]
id = "wiki-search"

[trainer]

[inference.model]
enable_auto_tool_choice = true
tool_call_parser = "hermes"

[inference.parallel]
tp = 2
dp = 3