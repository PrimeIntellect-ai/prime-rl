inference_gpu_ids = [0, 1, 2, 3]
trainer_gpu_ids = [4, 5, 6, 7]

max_steps = 1000
seq_len = 16384

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[wandb]
project = "service-agent"
name = "service-agent-4b"

[orchestrator]
batch_size = 1024
rollouts_per_example = 8

[orchestrator.client]
api_key_var = "VLLM_API_KEY"

[orchestrator.buffer]
easy_threshold = 1.0

# train on service-agent

[[orchestrator.env]]
id = "service-agent"
name = "library"
args = { domain = "library", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "restaurant"
args = { domain = "restaurant", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "helpdesk"
args = { domain = "helpdesk", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "government"
args = { domain = "government", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "festival"
args = { domain = "festival", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "clinic"
args = { domain = "clinic", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

[[orchestrator.env]]
id = "service-agent"
name = "car_rental"
args = { domain = "car_rental", user_model = "openai/Qwen/Qwen3-30B-A3B-Instruct-2507", user_base_url = "http://10.20.0.24:8000/v1", user_api_key_var = "VLLM_API_KEY" }

# eval tau2-bench

[orchestrator.eval]
interval = 20
num_examples = -1
rollouts_per_example = 1
eval_base_model = true

[orchestrator.eval.sampling]
temperature = 0.8

[[orchestrator.eval.env]]
id = "tau2-bench"
name = "tau2-retail"
args = { domain = "retail" }

[[orchestrator.eval.env]]
id = "tau2-bench"
name = "tau2-telecom"
args = { domain = "telecom" }

[trainer]

[inference]
gpu_memory_utilization = 0.9

[inference.model]
max_model_len = 16384
enable_auto_tool_choice = true
tool_call_parser = "hermes"

[log]
level = "debug"