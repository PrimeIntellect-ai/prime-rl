model_name = "PrimeIntellect/llama-2m-fresh"
max_samples = 32
batch_size = 8
enforce_eager = true

[sampling]
max_tokens = 64
