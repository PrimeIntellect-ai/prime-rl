total_steps = 3
batch_size = 32


[train]
name_model = "PrimeIntellect/llama-2m-fresh"
wandb = false

[train.data]
fake = false
timeout = 1000000000000000000000000
num_workers = 1
seq_length = 128

[train.train]
micro_bs = 8
torch_compile = false

[train.optim]
warmup_steps = 10
step_per_rollout = 2

[inference]
name_model = "PrimeIntellect/llama-2m-fresh"
max_samples = 100000
enforce_eager = true

[inference.sampling]
max_tokens = 128